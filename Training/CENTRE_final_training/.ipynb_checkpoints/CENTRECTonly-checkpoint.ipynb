{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324b6726-b05b-47b9-84cd-4858cd169f49",
   "metadata": {},
   "source": [
    "# CENTRE CT only training for Ekin's project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7164d0-cf5e-45a3-95a5-5785fa9f5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np # calculate the mean and standard deviation\n",
    "import xgboost as xgb # XGBoost stuff\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from numpy import sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b456fc5-6706-43e0-a5a5-4419c35047f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalparamsearch(com):\n",
    "    com['distance'] =com['distance'].abs()\n",
    "    com=com.sort_values('pair19')\n",
    "    com=com.reset_index(drop=True)\n",
    "    ''' function to do parameter search '''\n",
    "    cv_names=com[\"CV\"].unique()\n",
    "    myCViterator = []\n",
    "    for i in range(len(cv_names)):\n",
    "        trainIndices = com[ com['CV']!=cv_names[i] ].index.values.astype(int)\n",
    "        testIndices =  com[ com['CV']==cv_names[i] ].index.values.astype(int)\n",
    "        myCViterator.append( (trainIndices, testIndices) )\n",
    "\n",
    "\n",
    "    #run randomized search for optimal parameters\n",
    "\n",
    "    X_train= com.drop(['gene_id1','gene_id','symbol38','symbol19','pair','pair19','label','CV'], axis=1).copy()\n",
    "    y_train = com['label'].copy()\n",
    "    model = xgb.XGBClassifier(objective = \"binary:logistic\",scale_pos_weight=5,random_state=0)\n",
    "    param_grid = {\n",
    "            'max_depth': [4, 5, 6,8,10,12],\n",
    "            'learning_rate': [0.1, 0.05, 0.01],\n",
    "            'gamma': [0, 0.25, 1.0],\n",
    "            'reg_lambda': [0, 1.0, 10.0],\n",
    "            'n_estimators': [100,200,300,400,500],\n",
    "            'colsample_bytree': [0.5,0.6,0.7,0.9],\n",
    "            'subsample': [0.7, 0.9]\n",
    "        }\n",
    "    search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,scoring='f1', cv=myCViterator, n_jobs=12, refit=True)\n",
    "    result = search.fit(X_train, y_train)\n",
    "    print('est=%.3f, cfg=%s' % (result.best_score_, result.best_params_))\n",
    "    return(result.best_score_, result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c70a569-0ec0-4a39-a273-44ddcb08e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOptParams(com, best_params, pathtomodel):\n",
    "    X_train_xg= com.drop(['gene_id1', 'gene_id', 'symbol38', 'symbol19', 'pair', 'pair19', 'label', 'CV'], axis=1).copy()\n",
    "    y_train_xg = com['label'].copy()\n",
    "    clf_xgb = xgb.XGBClassifier(objective = \"binary:logistic\",scale_pos_weight=5,random_state=0,**best_params)\n",
    "    clf_xgb.fit(X_train_xg, y_train_xg)\n",
    "    clf_xgb.save_model(pathtomodel)\n",
    "    return(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d655885-a6b1-478e-bd78-dd0f555b48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVF1results(com, best_params):\n",
    "\n",
    "    cv_names=com[\"CV\"].unique()\n",
    "    d = dict(tuple(com.groupby('CV')))\n",
    "    result_all_xgboost={}\n",
    "    result_all_tf={}\n",
    "    result_cv_xg=[]\n",
    "    result_cv_tf=[]\n",
    "    for i in range(len(cv_names)):\n",
    "        cv_test=cv_names[i]\n",
    "        cv_train=[x for k,x in enumerate(cv_names) if k!=i]\n",
    "        X_test_xg = d[cv_test].drop(['gene_id1', 'gene_id', 'symbol38', 'symbol19', 'pair', 'pair19', 'label', 'CV'], axis=1).copy()\n",
    "        y_test_xg = d[cv_test]['label'].copy()\n",
    "        train_xg=pd.concat({k: d[k] for k in cv_train})\n",
    "        X_train_xg= train_xg.drop(['gene_id1', 'gene_id', 'symbol38', 'symbol19', 'pair', 'pair19', 'label', 'CV'], axis=1).copy()\n",
    "        y_train_xg = train_xg['label'].copy()\n",
    "        clf_xgb = xgb.XGBClassifier(objective = \"binary:logistic\",scale_pos_weight=5,random_state=0,**best_params)\n",
    "        clf_xgb.fit(X_train_xg, y_train_xg)\n",
    "        pred_s = clf_xgb.predict_proba(X_test_xg)\n",
    "        lr_probs =pred_s[:, 1]\n",
    "        yhat = clf_xgb.predict(X_test_xg)\n",
    "        result_cv = pd.DataFrame({'pred_prob':lr_probs,'pred_label': yhat,'true_label':y_test_xg})\n",
    "        result_cv_xg.append(f1_score(result_cv['true_label'], result_cv['pred_label']))\n",
    "        result_all_xgboost[cv_test]=result_cv\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    results_xg=pd.concat(result_all_xgboost)\n",
    "    \n",
    "    lr_precision_xg, lr_recall_xg, _ = precision_recall_curve(results_xg['true_label'], results_xg['pred_prob'])\n",
    "    lr_f1_xg, lr_auc_xg = f1_score(results_xg['true_label'], results_xg['pred_label']), auc(lr_recall_xg, lr_precision_xg)\n",
    "    print('xgboost HiC 12 fold CV:auc=%.3f' % lr_auc_xg)\n",
    "    print(lr_f1_xg)\n",
    "    print(result_cv_xg)\n",
    "\n",
    "    dist_precision, dist_recall, _=precision_recall_curve(com['label'],1/abs(com['distance']))\n",
    "    dist_auc = auc(dist_recall, dist_precision)\n",
    "    print('Distance:auc=%.3f' % (dist_auc))\n",
    "    ##1st f1 scores of CENTRE.MSI.MI\n",
    "    ##2nd f1 scores of CENTRE\n",
    "    return(lr_f1_xg, result_cv_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac397a93-a5ef-480e-b4cd-1d0151c3a791",
   "metadata": {},
   "source": [
    "### Consensus LcL training without Wilcoxon tests and CRUP cor (w/o Generic features except genomic distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03b26e5-a94d-4e14-be7a-989a8b228c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est=0.538, cfg={'subsample': 0.7, 'reg_lambda': 10.0, 'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1, 'gamma': 0.25, 'colsample_bytree': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lopez_s/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [15:34:40] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m centreMSIMImodel \u001b[38;5;241m=\u001b[39m trainOptParams(com, best_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/project/CRUP_scores/CENTRECT/inst/extdata/centre_modelCTandDist.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m##CV\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m f1_CENTREMIMSI, f1_CENTREMIMSICV \u001b[38;5;241m=\u001b[39m \u001b[43mCVF1results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mCVF1results\u001b[0;34m(com, best_params)\u001b[0m\n\u001b[1;32m     16\u001b[0m y_train_xg \u001b[38;5;241m=\u001b[39m train_xg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     17\u001b[0m clf_xgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,scale_pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mclf_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_xg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_xg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m pred_s \u001b[38;5;241m=\u001b[39m clf_xgb\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_xg)\n\u001b[1;32m     20\u001b[0m lr_probs \u001b[38;5;241m=\u001b[39mpred_s[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[1;32m   1496\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[0;32m-> 1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "traindatafile = \"Give path to train set file\"\n",
    "modelpath=\"Give path to where you want to save the model\n",
    "##Load consensusLclfile\n",
    "lcls = pd.read_csv(traindatafile, \n",
    "                     header=0, sep='\\t')\n",
    "\n",
    "## Drop generic features except distance\n",
    "lcls.drop(['cor_CRUP', 'combined_tests'], axis=1)\n",
    "\n",
    "       \n",
    "##Parameter search using Grid Search with 12-fold CV (Moore et al. scheme)\n",
    "com=lcls.fillna(0)\n",
    "    \n",
    "best_score, best_params = optimalparamsearch(com)\n",
    "\n",
    "##Train with opt parameters and save the CENTRECT model\n",
    "centreCTDT = trainOptParams(com, best_params, modelpath)\n",
    "\n",
    "##This is only to get a measure of performance\n",
    "f1_CENTRECTDT, f1_CENTRECTDT = CVF1results(com, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a410b8-bef1-4f81-9674-f9ad1a0809aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gene_id1', 'gene_id', 'symbol38', 'symbol19', 'pair', 'pair19',\n",
       "       'label', 'CV', 'EP_prob_enh.1', 'EP_prob_enh.2', 'EP_prob_enh.3',\n",
       "       'EP_prob_enh.4', 'EP_prob_enh.5', 'EP_prob_gene.1', 'EP_prob_gene.2',\n",
       "       'EP_prob_gene.3', 'EP_prob_gene.4', 'EP_prob_gene.5', 'PP_prob_enh.1',\n",
       "       'PP_prob_enh.2', 'PP_prob_enh.3', 'PP_prob_enh.4', 'PP_prob_enh.5',\n",
       "       'PP_prob_gene.1', 'PP_prob_gene.2', 'PP_prob_gene.3', 'PP_prob_gene.4',\n",
       "       'PP_prob_gene.5', 'distance', 'cor_CRUP', 'combined_tests',\n",
       "       'reg_dist_enh', 'norm_reg_dist_enh', 'reg_dist_prom',\n",
       "       'norm_reg_dist_prom', 'RNA_seq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcls.columns ## order ibn which features should be fed to classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
